---
title: "Data 607 Project 3"
date: "2022-10-14"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 4
    number_sections: false
    highlight: pygments
    theme: cerulean
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE ,warning = FALSE, message = FALSE)

```

## PART 1 -  Project 1 Description
Create a short document, with the names of group members. You should briefly describe your collaboration tool(s) you’ll use as a group, including for communication, code sharing, and project documentation. You should have identified your data sources, where the data can be found, and how to load it.  And you should have created at least a logical model for your normalized database, and produced an Entity-Relationship (ER) diagram documenting your database design


<br/>

### Project 3 Team Members

* Sanielle Worrell
* Vladimir Nimchenko
* Jose Rodriguez
* Johnny Rodriguez


> #### Team Insights
* Key to making progress was getting organized
* We met several times in Zoom working sessions and communicated over Slack
* Divyed-up parts of the project to members


<br/>

### Project Tools

The team is using R Studio Cloud (https://rstudio.cloud) for collaboration and code development.  This allows us to view and share code within the project. We are using R Markdown within RStudio Cloud for project documentation to publish through RPubs (https://rpubs.com) . To create the ERD, the team used Quick Database Diagrams (https://www.quickdatabasediagrams.com).  Source CSV and RMD files are saved in a github repo so files can be accessed centrally (https://github.com/johnnydrodriguez/data607_project3) In addition to this, the team communicates over Zoom and Slack.

<br/>

> #### Project Tools Insights
* Initially, we looked for collaboration tools that allowed for real time editing (like Google Docs, or Online MS Word).  Google Collab with the R engine was an option we experience some collaboration clunkiness with the tool
* Ultimately, RStudio Cloud was not a tool we could use for collaboration either for the project.  Despite setting up a collaborative work space and upgrading the service tier to increase performance and availability, the cloud version was too limiting for team use.
* The team began using Github as a central repository for shared code and collaborated in real time over Zoom sessions. This was effective in moving the project forward.


<br/>

### Project 3 Data Sources

The data used to answer the question is taken from Glassdoor via Kaggle.  The data was scrapped from Glassdoor and posted to the site.

Source:
https://www.kaggle.com/datasets/nikhilbhathi/data-scientist-salary-us-glassdoor?resource=download

Source CSV  (Uncleaned for Project): 
https://raw.githubusercontent.com/johnnydrodriguez/data607_project3/main/glassdoor_2021.csv

<br/>

> #### Data Sources Insights
* Finding datasets that answered this specific question we challening to find. 
* We correctly hypothesized that a possible way to locate date were from job sites (GlassDoor, Indeed, LinkedIn), and federal labor (Bureau of Labor Statistics) and higher education government sites (Integrated Postsecondary Education Data System) .  
* Job sites proved challenging as API or public data sets were not available -- at least not without significantly more effort performing scraping work or paid fees.  
* The Federal government sites are data-rich but job titles, skills and other variables that may have directly helped answer the question where typically aggregated generically under Data Science or Computer Information variables.
* The Glassdoor data used in the project was scraped and made available through Kaggle.


<br/>

### Project 3 Entity Relationship Diagram

https://github.com/johnnydrodriguez/data607_project3/blob/main/QuickDBD-export.png

<br/>

> #### ERD Insights
* The Quick Database diagram website was easy to use to create the ERD.  
* Once the project got underway, a discussion point was whether to adjust.  For example, our initial design required only 3 tables: Company, Job and Tech Skills.  However, the data included variable not available in their own columns - rather, they were buried as strings within the Job Descriptions.  
* This allowed us to identify two other types of skills - academic domain skills (Statistics, Math, Economics) and soft skills (problem-solving, critical thinking, decision-making, etc)
* We determined the these variable were best used as >>>> variable in their own tables >>>> additional columns in the original 3 table design.

<br/>



```{r img-with-knitr, echo=FALSE, fig.align='center', out.width='100%', fig.cap='Data Science Valuble Skills ERD'}

knitr::include_graphics("https://raw.githubusercontent.com/johnnydrodriguez/data607_project3/main/QuickDBD-export.png")

```


---

## PART 2 - Which are the most valued data science skills?

<br/>

### Prepping the Environment Project Packages and Libraries

```{r echo = FALSE ,warning = FALSE, message = FALSE}


library(tidyverse)
library(RMySQL)
library(ggplot2)
library(aws.s3)
library(dplyr)
library(stringr)
library(tidyr)


```

<br/>

```{r Set Passwords and Keys, echo=FALSE}
AWS_ACCESS_KEY_ID <- "AKIA4QMABP5OYQY2NUG6"
AWS_SECRET_ACCESS_KEY <- "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"
password <- "Iu6T2vCiukfUsfULYKqQ"
```


<br/>

## Connecting to the SQL database and loading raw data
```{r}


#Connect to S3------------------------------------------------------------------
#Use IAM login credentials/Set to "read-only"
Sys.setenv("AWS_ACCESS_KEY_ID" = AWS_ACCESS_KEY_ID,
           "AWS_SECRET_ACCESS_KEY" = AWS_SECRET_ACCESS_KEY)

#Check bucket
get_bucket("data-skills-p3")

#Load csv file from s3 into a df
jobs_df <- aws.s3::s3read_using(read.csv, object = "s3://data-skills-p3/glassdoor_2021.csv")



glimpse(jobs_df, n = 1)


```


<br/>

## Data clean up and transformation

```{r}
# Rename Columns
#jobs_df <- jobs_df %>%
#rename("job_title" = 2, "est_salary" = 3, "job_description" = 4, "company" = 6, "ownership" = 11)


# Remove duplicates
jobs_unique <- jobs_df %>% distinct(Job.Description,Company.Name, .keep_all = TRUE)

# Clean up commas in data
jobs_unique$Job.Description <- gsub("’", "'", jobs_unique$Job.Description)

# Identify keywords
education <- c("Masters", "Bachelors", "Master's", "Bachelor's", "Phd", "PhD", "Ph.D")
jobs_unique$education <- mapply(function(x)paste(education[str_detect(x,(education))],
                                        collapse = ","), jobs_unique$Job.Description)

# Skills Extraction from Job Description
# Convert values in 1 and 0
jobs_unique <- jobs_unique %>%
  mutate(DA = str_match(Job.Description, '.*(Data Analy).*')[,2],
        R = str_match(Job.Description, '.*(\\sR\\s).*')[,2],
       API = str_match(Job.Description, '.*(API).*')[,2],
       Viz = str_match(Job.Description, '.*(Visualization).*')[,2],
       ML = str_match(Job.Description, '.*(Machine Learning | ML).*')[,2],
       #   LR = str_match(job_description, '.*(Logistic Regression).*')[,2],
       #   ETL = str_match(job_description, '.*(ETL).*')[,2],
        #  PD = str_match(job_description, '.*(Predictive).*')[,2],
         # ST = str_match(job_description, '.*(Stat).*')[,2],
       #  EC = str_match(job_description, '.*(Economics).*')[,2],
        # ST = str_match(job_description, '.*(Math).*')[,2],
        # PS = str_match(job_description, '.*(problem-solving).*')[,2],
        # CM = str_match(job_description, '.*(communication).*')[,2],
       #  DM = str_match(job_description, '.*(decision-making).*')[,2],
        # CR = str_match(job_description, '.*(creativity).*')[,2],
        CT = str_match(Job.Description, '.*(critical thinking).*')[,2]
         )

glimpse(jobs_unique)


#Tidy/Transform data from the glass door data and create "Company" data frame.
# create the Company data frame from the glass door data
Company <-select(jobs_unique, c('index','Rating', 'Company.Name','Location','Headquarters','Size','Founded','Type.of.ownership','Industry','Sector','Revenue','Competitors','company_txt','Age'))
# Change the "index" column to "CompanyID"
colnames(Company)[colnames(Company)== "index"] <-"CompanyID"
# Change the "Rating" column to "Company_Rating"
colnames(Company)[colnames(Company)== "Rating"] <-"Column_Rating"
# Change the "Company.Name" column to "Company_Name"
colnames(Company)[colnames(Company)== "Company.Name"] <-"Company_Name"
# Change the "Headquarters" column to "HQ_Address"
colnames(Company)[colnames(Company)== "Headquarters"] <-"HQ_Address"
# Change the "Type.of.ownership" column to "type_of_ownership"
colnames(Company)[colnames(Company)== "Type.of.ownership"] <-"type_of_ownership"
# Change the "Age" column to "Company_Age"
colnames(Company)[colnames(Company)== "Age"] <-"Company_Age"


#Tidy/Transform data from the glass door data and create "Jobs" data frame.
# create the Company data frame from the glass door data
Jobs <-select(jobs_unique, c('index','Job.Title', 'Salary.Estimate','Job.Description','Hourly','Lower.Salary','Upper.Salary','Avg.Salary.K.','Job.Location','job_title_sim','seniority_by_title','Degree', 'education'))
# Change the "index" column to "JobID"
colnames(Jobs)[colnames(Jobs)== "index"] <-"JobID"
# Change the "Job.Title" column to "Job_Title"
colnames(Jobs)[colnames(Jobs)== "Job.Title"] <-"Job_Title"
# Change the "Salary.Estimate" column to "Salary_Estimate"
colnames(Jobs)[colnames(Jobs)== "Salary.Estimate"] <-"Salary_Estimate"
# Change the "Job.Description" column to "Job_Description"
colnames(Jobs)[colnames(Jobs)== "Job.Description"] <-"Job_Description"
# Change the "Lower.Salary" column to "Lower_Salary(K)"
colnames(Jobs)[colnames(Jobs)== "Lower.Salary"] <-"Lower_Salary(K)"
# Change the "Upper.Salary" column to "Upper_Salary(K)"
colnames(Jobs)[colnames(Jobs)== "Upper.Salary"] <-"Upper_Salary(K)"
# Change the "Avg.Salary.K." column to "Avg_Salary(K)"
colnames(Jobs)[colnames(Jobs)== "Avg.Salary.K."] <-"Avg_Salary(K)"
# Change the "Job.Location" column to "Job_Location"
colnames(Jobs)[colnames(Jobs)== "Job.Location"] <-"Job_Location"



Tech <-select(jobs_unique, c("index","Python","spark","aws","excel","sql","sas","keras","pytorch","scikit","tensor","hadoop","tableau","bi","flink","mongo","google_an"))
# Change the "index" column to "TechID"
colnames(Tech)[colnames(Tech)== "index"] <-"TechID"


```


<br/>

### Connect to the SQL database and uploads tables

```{r}

#password <- .rs.askForPassword("Database Password:")
endpoint <- "database-1.c4xyb2t3srpc.us-east-1.rds.amazonaws.com"
port <- 3306
username <- "admin"
dbname <- "database1"
region <- "us-east-1a"

# Connect to the database using an IAM authentication token.
con <- DBI::dbConnect(
  RMySQL::MySQL(),
  host = "database-1.c4xyb2t3srpc.us-east-1.rds.amazonaws.com",
  port = 3306,
  db = "database1",
  user = "admin",
  password = password
)

## TEST DATABASE CONNECTION
class(con)

#To drop a table from rds database
dbSendQuery(con, "DROP TABLE IF EXISTS company,jobs,tech")

#Uploading tables to AWS RDS - MySQL Instance
dbWriteTable(conn = con, name = 'jobs', value = as.data.frame(Jobs))
dbWriteTable(conn = con, name = 'tech', value = as.data.frame(Tech))
dbWriteTable(conn = con, name = 'company', value = as.data.frame(Company))
#dbWriteTable(conn = con, name = 'skills', value = as.data.frame(Skills))


#List database tables
tables <- dbListTables(con) # load tables in rds to variable
str(tables) # Display structure of tables

#To drop a table from rds database
dbSendQuery(con, "DROP TABLE IF EXISTS company,jobs,tech")


jobs_tbl <- dbGetQuery(con, "SELECT * FROM jobs")
tech_tbl <- dbGetQuery(con, "SELECT * FROM tech")
company_tbl <- dbGetQuery(con, "SELECT * FROM company")
skills_tbl <- dbGetQuery(con, "SELECT * FROM skills")

```


```{r}
company_tbl
   
```
```{r Joining Tables}
df_join1 <- left_join(jobs_tbl, tech_tbl, by = c("JobID" = "TechID"))
df_join2 <- left_join(df_join1, company_tbl, by = c("JobID" = "CompanyID"))

```
Clean up titles in Job titles column in education by formatting to uppercase and replacing misspellings
```{r}
Jobs$job_title_sim <- str_to_title(Jobs$job_title_sim)
Jobs$job_title_sim <- str_replace(Jobs$job_title_sim, "Data Scientist Project Manager", "Data Scientist PM")
Jobs$job_title_sim <- str_replace(Jobs$job_title_sim, "Data Analitics", "Data Analytics")
```

Plot (remove na from plot in Job title )
```{r}
ggplot(Jobs[which(Jobs$job_title_sim != "Na"),], aes(x = job_title_sim, y = `Avg_Salary(K)`, fill = job_title_sim)) +
       geom_bar(stat="identity")+ 
       theme_bw()+
       scale_fill_brewer(palette="Set1")+
       labs(title = "Salary by Job Title",
       x = "Job Title",
       y = "Average Salary (K)", fill = "Job Titles")+
  theme(axis.text.x = element_text(angle=0, vjust=0.6 ))+ coord_flip()
```
Clean up data in education by removing period

```{r}
Jobs$education <-gsub("\\.","",Jobs$education)
```


Clean up keywords in education
```{r}
Jobs$education <- str_replace(Jobs$education, "Masters", "Master's")
Jobs$education <- str_replace(Jobs$education, "Bachelors", "Bachelor's")
Jobs$education <- str_replace(Jobs$education, "PhD,PhD", "PhD")
```




Plot chart - Job description Salary by Education
```{r}
ggplot(Jobs[which(Jobs$education != ""),], aes(x = education, y = `Avg_Salary(K)`, fill = education)) +
       geom_bar(stat="identity")+ 
       theme_bw()+
       scale_fill_brewer(palette="Set1")+
       labs(title = "Job description Salary by Education",
       x = "Education",
       y = "Average Salary (K)", fill = "Education")+
  theme(axis.text.x = element_text(angle=0, vjust=0.6 ))+ coord_flip()
```
Plot chart - Job titles by profession and education level
```{r}
ggplot(data = Jobs[which(Jobs$education != "" & Jobs$job_title_sim != "Na"),], aes(x = `job_title_sim`, fill = education)) + 
  geom_bar()+
  scale_fill_brewer(palette="Set3")+
  theme_bw()+
  labs(title = " Job titles by profession and education level",
       caption = "Does not include jobs that did not specify education",
       x = "Job Title",
       fill = "Education")+
  theme(axis.text.x = element_text(angle=0, vjust=0.6 ))+ coord_flip()
```

```{r}
skills <- read.csv("https://raw.githubusercontent.com/johnnydrodriguez/data607_project3/main/sql_tables/skills_tbl.csv")
```

Merging tables (jobs and skills)
```{r}
jobs_skills <- cbind(Jobs, skills)
```

Plot Chart
```{r}
data_ggp <- data.frame(x = jobs_skills$`Avg_Salary(K)`,
                       y = c(jobs_skills$Data_Analysis,jobs_skills$Crit_Thinking,jobs_skills$R),
                       group = c(rep("y1", nrow(jobs_skills)),
                                 rep("y2", nrow(jobs_skills)),
                                 rep("y3", nrow(jobs_skills))))
 
```   

```{r}
ggp <- ggplot(data_ggp, aes(x, y, col = group)) +             
  geom_point()
ggp                              
```

```
## Analysis

---

<br/>

## Conclusion
